# 3. 大模型检索增强技术RAG

在大语言模型（LLM）飞速发展的今天，LLMs 正不断地充实和改进我们周边的各种工具和应用。如果说现在基于 LLM 最火热的应用技术是什么，检索增强生成（RAG，Retrieval Augmented Generation）技术必占据重要的一席。RAG 最初是为了解决 LLM 的各类问题的产生的，但后面大家发现在现阶段的很多企业痛点上，使用RAG好像是更好的解决方案。在介绍 RAG 之前，我们先来看一下现在LLM存在的问题。

LLM的问题
尽管LLM拥有令人印象深刻的能力，但是它们还面临着一些问题和挑战：

* 幻觉问题：大模型的底层原理是基于概率，在没有答案的情况下经常会胡说八道，提供虚假信息。

* 时效性问题：规模越大（参数越多、tokens 越多），大模型训练的成本越高。类似 ChatGPT3.5，起初训练数据是截止到 2021 年的，对于之后的事情就不知道了。而且对于一些高时效性的事情，大模型更加无能为力，比如帮我看看今天晚上有什么电影值得去看？这种任务是需要去淘票票、猫眼等网站先去获取最新电影信息的，大模型本身无法完成这个任务。

* 数据安全：OpenAI 已经遭到过几次隐私数据的投诉，而对于企业来说，如果把自己的经营数据、合同文件等机密文件和数据上传到互联网上的大模型，那想想都可怕。既要保证安全，又要借助 AI 能力，那么最好的方式就是把数据全部放在本地，企业数据的业务计算全部在本地完成。而在线的大模型仅仅完成一个归纳的功能，甚至，LLM 都可以完全本地化部署。

解决这些挑战对于 LLMs 在各个领域的有效利用至关重要。一个有效的解决方案是集成检索增强生成（RAG）技术，该技术通过获取外部数据来响应查询来补充模型，从而确保更准确和最新的输出。主要表现方面如下：

有效避免幻觉问题：虽然无法 100% 解决大模型的幻觉问题，但通过 RAG 技术能够有效的降低幻觉，在软件系统中结合大模型提供幂等的API接口就可以发挥大模型的重要作用。

经济高效的处理知识&开箱即用：只需要借助信息检索和向量技术，将用户的问题和知识库进行相关性搜索结合，就能高效的提供大模型不知道的知识，同时具有权威性。

数据安全：企业的数据可以得到有效的保护，通过私有化部署基于 RAG 系统开发的AI产品，能够在体验AI带来的便利性的同时，又能避免企业隐私数据的泄漏。

![RAG_example](https://img-blog.csdnimg.cn/img_convert/568d87172aaa9f21fc798658fdff2793.webp?x-oss-process=image/format,png)



上图展示了 RAG 如何使 ChatGPT 能够提供超出其初始训练数据的精确答案。
