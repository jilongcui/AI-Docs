# 4.1 提示工程介绍

提示工程是一个较新的学科，应用于开发和优化提示词（Prompt），帮助用户有效地将语言模型用于各种应用场景和研究领域。

提示工程(PromptEngineering)也叫**指令工程**，就是探讨如何设计出最佳提示词，用于指导语言模型帮助我们高效完成某项任务。

Prompt(提示词) 即发送给大模型的指令，比如「讲个故事」等。

- Prompt 是 AGI时代的「编程语」
- Prompt 工程是 AGI时代的「软件工程」
- 提示工程师是 AGI 时代的「程序员」

### 提示词格式

标准提示词应该遵循以下格式：

```text
<问题>?
```

或

```text
<指令>
```

你可以将其格式化为问答（QA）格式，这在许多问答数据集中是标准格式，如下所示：

```text
Q: <问题>?
A: 
```

当像上面那样提示时，这也被称为**零样本提示**

基于以上标准格式（format），一种流行且有效的提示技术被称为**少样本提示**，其中你提供示例（即示范）。你可以按照以下格式组织少样本提示：

```text
<问题>?
<答案>
<问题>?
<答案>
<问题>?
<答案>
<问题>?
```

问答格式的版本看起来像这样：

```text
Q: <问题>?
A: <答案>
Q: <问题>?
A: <答案>
Q: <问题>?
A: <答案>
Q: <问题>?
A:
```

### prompt的构成

#### 提示词要素

Prompt的组成主要包括指令(Instruction)、输入数据(Input Data)、上下文(Context)以及输出指示器(0utput Indicator)，这些构成了提示词的核心要素，对于设计有效的AI交互至关重要;

- **指令**: 想要模型执行的特定任务或指令。
- **[上下文](https://zhida.zhihu.com/search?content_id=246856288&content_type=Article&match_order=2&q=上下文&zhida_source=entity)**: 包含外部信息或额外的上下文信息，引导语言模型更好地响应。
- **输入数据:** 用户输入的内容或问题。
- **输出指示**: 指定输出的类型或格式。

从Prompt的内容和形式，可以将其分为:

- **零样本提示(Zero-shot prompts)**: 用户仅提供了一个任务描述;
- **少样本提示(Few-shot prompts)**: 用户提供如何完成任务的示例: （给出例子）

### 零样本提示

经过大量数据训练并调整指令的LLM能够执行零样本任务

提示

```text
将文本分类为中性、负面或正面。
文本：我认为这次假期还可以。
情感：
```

输出

```text
中性
```

在上面的提示中，我们没有向模型提供任何示例——这就是零样本能力的作用。

指令调整已被证明可以改善零样本学习[Wei等人（2022）(opens in a new tab)](https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2109.01652.pdf)。指令调整本质上是在通过指令描述的数据集上微调模型的概念。此外，[RLHF(opens in a new tab)](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1706.03741)（来自人类反馈的强化学习）已被采用以扩展指令调整，其中模型被调整以更好地适应人类偏好。这一最新发展推动了像ChatGPT这样的模型。

### 少样本提示

当零样本不足以满足给出描述时，就需要给是例子，来得到期望得到的结果。

根据 [Touvron et al. 2023(opens in a new tab)](https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2302.13971.pdf) 等人的在 2023 年的论文，当模型规模足够大时，小样本提示特性开始出现 [(Kaplan et al., 2020)(opens in a new tab)](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2001.08361)。

让我们通过[Brown等人2020年(opens in a new tab)](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2005.14165)提出的一个例子来演示少样本提示。在这个例子中，任务是在句子中正确使用一个新词。

*提示：*

```text
“whatpu”是坦桑尼亚的一种小型毛茸茸的动物。一个使用whatpu这个词的句子的例子是：
我们在非洲旅行时看到了这些非常可爱的whatpus。
“farduddle”是指快速跳上跳下。一个使用farduddle这个词的句子的例子是：
```

*输出：*

```text
当我们赢得比赛时，我们都开始庆祝跳跃。
```

我们可以观察到，模型通过提供一个示例（即1-shot）已经学会了如何执行任务。对于更困难的任务，我们可以尝试增加演示。

**少样本提示的限制**

标准的少样本提示对许多任务都有效，但仍然不是一种完美的技术，特别是在处理更复杂的推理任务时。

让我们演示为什么会这样。

```text
这组数字中的奇数加起来是一个偶数：15、32、5、13、82、7、1。
A：
```

如果我们再试一次，模型输出如下：

```text
是的，这组数字中的奇数加起来是107，是一个偶数。
```

这没用。似乎少样本提示不足以获得这种类型的[推理问题](https://zhida.zhihu.com/search?content_id=246856288&content_type=Article&match_order=1&q=推理问题&zhida_source=entity)的可靠响应。上面的示例提供了任务的基本信息。如果您仔细观察，我们引入的任务类型涉及几个更多的推理步骤。换句话说，如果我们将问题分解成步骤并向模型演示，这可能会有所帮助。最近，[思维链（CoT）提示(opens in a new tab)](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2201.11903)已经流行起来，以解决更复杂的算术、常识和符号推理任务。
